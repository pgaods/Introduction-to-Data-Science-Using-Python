{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lecture, we study the theory behind autoencoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GAO\\.conda\\envs\\gao_uat\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\GAO\\.conda\\envs\\gao_uat\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\GAO\\.conda\\envs\\gao_uat\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\GAO\\.conda\\envs\\gao_uat\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\GAO\\.conda\\envs\\gao_uat\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\GAO\\.conda\\envs\\gao_uat\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os  \n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import io\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "path=\"C:\\\\Users\\\\GAO\\\\python workspace\\\\GAO_Jupyter_Notebook\\\\Datasets\"\n",
    "os.chdir(path)\n",
    "\n",
    "print(tf.__version__) # for TensorFlow 2.6 version, go to anaconda prompt and then delete the keras library (pip uninstall keras, see https://stackoverflow.com/questions/60269982/tensorflow-keras-alreadyexistserror)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. The Theory of Autoencoders\n",
    "\n",
    "Autoencoders are an unsupervised learning technique in which we leverage neural networks for the task of representation learning. Specifically, we'll design a neural network architecture such that we impose a bottleneck in the network which forces a compressed knowledge representation of the original input. If the input features were each independent of one another, this compression and subsequent reconstruction would be a very difficult task. However, if some sort of structure exists in the data (ie. correlations between input features), this structure can be learned and consequently leveraged when forcing the input through the network's bottleneck. Suppose that we have input data $x$ with the autoencoder neural network $m(.)$. The idea is to send $x$ via $m(.)$ to project the input onto itself, hoping to find some type of representation in the process.\n",
    "\n",
    "Below is an intuitive picture of what autoencoders may look like. Autoencoders can have different network structures but the basic idea comes from the picture below. We can take an unlabeled dataset $x$ and frame it as a supervised learning problem tasked with outputting $x$, a reconstruction of the original input $x$. This network can be trained by minimizing the reconstruction error, which measures the differences between our original input and the consequent reconstruction. The bottleneck is a key attribute of our network design; without the presence of an information bottleneck, our network could easily learn to simply memorize the input values by passing these values along through the network. In other words, in the picture, the hidden layers must have lower dimensionality than the dimensionality of the input, therefore 'compressing' the original data and learning its representation. In other words, the point of the bottleneck is to constrain the amount of information that can traverse the full network, forcing a learned compression of the input data. Below is a conceptual description of what an autoencoder looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/3285/1*ZEvDcg1LP7xvrTSHt0B5-Q@2x.png\" width=\"400\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://miro.medium.com/max/3285/1*ZEvDcg1LP7xvrTSHt0B5-Q@2x.png\", width=400, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, if we were to construct a linear network (ie. without the use of nonlinear activation functions at each layer) we would observe a similar dimensionality reduction as observed in PCA.\n",
    "\n",
    "The ideal autoencoder model balances the following:\n",
    "\n",
    "   - sensitive to the inputs enough to accurately build a reconstruction;\n",
    "   - insensitive enough to the inputs that the model doesn't simply memorize or overfit the training data.\n",
    "   \n",
    "This trade-off forces the model to maintain only the variations in the data required to reconstruct the input without holding on to redundancies within the input. For most cases, this involves constructing a loss function where one term encourages our model to be sensitive to the inputs (i.e. reconstruction loss function $l(x,x'$) adopting the notation from the above picture and a second term discourages memorization or overfitting; that is, an added regularizer). This is the most natural way of reframing the problem, but in reality, there are other ways to achieve the same goal (an example is the sparse autoencoder, which will be discussed later). But the overall idea is the same: we need to balance the need between input reconstruction and overfitting the model.\n",
    "\n",
    "In general, an autoencoders is a specific type of feedforward neural network where the input is the same as the output. They compress the input into a lower-dimensional code and then reconstruct the output from this representation. The code is a compact 'summary' or 'compression' of the input, also called the **latent-space representation**. An autoencoder consists of 3 components: **encoder**, **code** and **decoder**. The encoder compresses the input and produces the code, the decoder then reconstructs the input only using this code. The idea is that our input data is converted into an encoding vector where each dimension represents some learned attribute about the data. Our encoder network is outputting a single value for each encoding dimension. The decoder network then subsequently takes these values and attempts to recreate the original input. So really we are learning the identity function, but with a twist. \n",
    "\n",
    "Below is an example of an autoencoder taking the image input data ($x$) through the encoder and decoder phase and then writes out a reconstructed value ($\\hat{x}$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/958/1*MMRDQ4g3QvQNc7iJsKM9pg@2x.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://miro.medium.com/max/958/1*MMRDQ4g3QvQNc7iJsKM9pg@2x.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different types of autoencoders. There are 5 popular types of autoencoders: 1) **simple (undercomplete) autoencoders**, 2) **sparse autoencoders (SAEs)**, 3) **denoising autoencoders (DAEs)** 4) **contractive autoencoders (CAEs)**, and 5) **variational autoencoders (VAEs)**. They all have the same idea but have different network topologies. For all these models, VAEs require the most detailed explanation, so we will ignore this type of network in this tutorial. We will go over all the theory for the rest of the model types.\n",
    "\n",
    "##### 1. Simple (Undercomplete) Autoencoders\n",
    "\n",
    "The simplest architecture for constructing an autoencoder is to constrain the number of nodes present in the hidden layer(s) of the network, limiting the amount of information that can flow through the network. By penalizing the network according to the reconstruction error, our model can learn the most important attributes of the input data and how to best reconstruct the original input from an \"encoded\" state. Ideally, this encoding will learn and describe latent attributes of the input data. An undercomplete autoencoder has no explicit regularization term; we simply train our model according to the reconstruction loss. Thus, our only way to ensure that the model isn't memorizing the input data is the ensure that we've sufficiently restricted the number of nodes in the hidden layer(s). Below is what the model looks likez, notice that we can have more than 1 hidden layers, with $a$'s denoting the hidden layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.jeremyjordan.me/content/images/2018/03/Screen-Shot-2018-03-07-at-8.24.37-AM.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpath=\"https://www.jeremyjordan.me/content/images/2018/03/Screen-Shot-2018-03-07-at-8.24.37-AM.png\"\n",
    "Image(url=mpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because neural networks are capable of learning nonlinear relationships, this can be thought of as a more powerful (nonlinear) generalization of PCA. Whereas PCA attempts to discover a lower dimensional hyperplane which describes the original data, autoencoders are capable of learning nonlinear manifolds. The difference between these two approaches is visualized below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.jeremyjordan.me/content/images/2018/03/Screen-Shot-2018-03-07-at-8.52.21-AM.png\" width=\"350\" height=\"350\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpath=\"https://www.jeremyjordan.me/content/images/2018/03/Screen-Shot-2018-03-07-at-8.52.21-AM.png\"\n",
    "Image(url=mpath, width=350, height=350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For higher dimensional data, autoencoders are capable of learning a complex representation of the data (manifold) which can be used to describe observations in a lower dimensionality and correspondingly decoded into the original input space. Below is an example of nonlinear manifold learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.jeremyjordan.me/content/images/2018/03/LinearNonLinear.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpath=\"https://www.jeremyjordan.me/content/images/2018/03/LinearNonLinear.png\"\n",
    "Image(url=mpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the fact that we'd like our model to discover latent attributes within our data, it's important to ensure that the autoencoder model is not simply learning an efficient way to memorize the training data. Similar to supervised learning problems, we can employ various forms of regularization to the network in order to encourage good generalization properties; these discussion lead to sparse autoencoders.\n",
    "\n",
    "##### 2. Sparse Autoencoders\n",
    "\n",
    "Sparse autoencoders offer us an alternative method for introducing an information bottleneck without requiring a reduction in the number of nodes at our hidden layers. Rather, we'll construct our loss function such that we penalize activations within a layer. For any given observation, we'll encourage our network to learn an encoding and decoding which only relies on activating a small number of neurons. It's worth noting that this is a different approach towards regularization, as we normally regularize the weights of a network, not the activations. \n",
    "\n",
    "A generic sparse autoencoder is visualized below where the opacity of a node corresponds with the level of activation. It's important to note that the individual nodes of a trained model which activate are data-dependent; different inputs will result in activations of different nodes through the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.jeremyjordan.me/content/images/2018/03/Screen-Shot-2018-03-07-at-1.50.55-PM.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpath=\"https://www.jeremyjordan.me/content/images/2018/03/Screen-Shot-2018-03-07-at-1.50.55-PM.png\"\n",
    "Image(url=mpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One result of this fact is that we allow our network to sensitize individual hidden layer nodes toward specific attributes of the input data. Whereas an undercomplete autoencoder will use the entire network for every observation, a sparse autoencoder will be forced to selectively activate regions of the network depending on the input data. As a result, we've limited the network's capacity to memorize the input data without limiting the networks capability to extract features from the data. This allows us to consider the latent state representation and regularization of the network separately, such that we can choose a latent state representation (ie. encoding dimensionality) in accordance with what makes sense given the context of the data while imposing regularization by the sparsity constraint.\n",
    "\n",
    "There are two main ways by which we can impose this sparsity constraint; both involve measuring the hidden layer activations for each training batch and adding some term to the loss function in order to penalize excessive activations. These terms are:\n",
    "\n",
    "   - L1 regularization: we can add a term to our loss function that penalizes the absolute value of the vector of activations $a(.)$ in layer $h$ for observation $i$, scaled by a tuning parameter $\\lambda$: $l(x, \\hat{x})+\\lambda\\sum_{i}|a^{(h)}|$.\n",
    "   - KL-Divergence: in essence, KL-divergence is a measure of the difference between two probability distributions. We can define a sparsity parameter $\\rho$ which denotes the average activation of a neuron over a collection of samples. This expectation can be calculated as $\\rho_{j}=\\frac{1}{n}\\sum_{i}a^{(h)}(x)$ where the subscript $j$ denotes the specific neuron in layer $h$, summing the activations for $n$ training observations denoted individually as $x$. In essence, by constraining the average activation of a neuron over a collection of samples we're encouraging neurons to only fire for a subset of the observations. We can describe $\\rho$ as a Bernoulli random variable such that we can leverage the KL divergence to compare the ideal distribution $\\rho$ to the observed distributions over all hidden layer nodes $\\hat{\\rho}$: $l(x, \\hat{x})+\\lambda\\sum_{j}\\text{KL}(\\rho, \\hat{\\rho}_{j})$.\n",
    "   \n",
    "##### 3. Denoising Autoencoders (DAEs)\n",
    "\n",
    "Another approach towards developing a generalizable model is to slightly corrupt the input data but still maintain the uncorrupted data as our target output. This method is called denoising autoencoders. Here, our model isn't able to simply develop a mapping which memorizes the training data because our input and target output are no longer the same. Rather, the model learns a vector field for mapping the input data towards a lower-dimensional manifold; if this manifold accurately describes the natural data, we've effectively \"canceled out\" the added noise. Let's see a picture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.jeremyjordan.me/content/images/2018/03/Screen-Shot-2018-03-09-at-10.12.59-PM.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpath=\"https://www.jeremyjordan.me/content/images/2018/03/Screen-Shot-2018-03-09-at-10.12.59-PM.png\"\n",
    "Image(url=mpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above figure visualizes the vector field described by comparing the reconstruction of $x$ with the original value of $x$. The yellow points represent training examples prior to the addition of noise. As we can see, the model has learned to adjust the corrupted input towards the learned manifold.\n",
    "\n",
    "It's worth noting that this vector field is typically only well-behaved in the regions where the model has observed during training. In areas far away from the natural data distribution, the reconstruction error is both large and does not always point in the direction of the true distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.jeremyjordan.me/content/images/2018/03/Screen-Shot-2018-03-10-at-10.17.44-AM.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpath=\"https://www.jeremyjordan.me/content/images/2018/03/Screen-Shot-2018-03-10-at-10.17.44-AM.png\"\n",
    "Image(url=mpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Contractive Autoencoders (CAEs)\n",
    "\n",
    "One would expect that for very similar inputs, the learned encoding would also be very similar. We can explicitly train our model in order for this to be the case by requiring that the derivative of the hidden layer activations are small with respect to the input. In other words, for small changes to the input, we should still maintain a very similar encoded state. This is quite similar to a denoising autoencoder in the sense that these small perturbations to the input are essentially considered noise and that we would like our model to be robust against noise. Put in other words, \"denoising autoencoders make the reconstruction function (ie. decoder) resist small but Ô¨Ånite-sized perturbations of the input, while contractive autoencoders make the feature extraction function (ie. encoder) resist infinitesimal perturbations of the input.\" (see https://arxiv.org/abs/1211.4246)\n",
    "\n",
    "Because we're explicitly encouraging our model to learn an encoding in which similar inputs have similar encodings, we're essentially forcing the model to learn how to contract a neighborhood of inputs into a smaller neighborhood of outputs. Notice how the slope (i.e. derivative) of the reconstructed data is essentially zero for local neighborhoods of input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.jeremyjordan.me/content/images/2018/03/Screen-Shot-2018-03-10-at-12.25.43-PM.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpath=\"https://www.jeremyjordan.me/content/images/2018/03/Screen-Shot-2018-03-10-at-12.25.43-PM.png\"\n",
    "Image(url=mpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can accomplish this by constructing a loss term which penalizes large derivatives of our hidden layer activations with respect to the input training examples, essentially penalizing instances where a small change in the input leads to a large change in the encoding space.\n",
    "\n",
    "we can craft our regularization loss term as the squared Frobenius norm of the Jacobian matrix $J$ for the hidden layer activations with respect to the input observations. A Frobenius norm is essentially an L2 norm for a matrix and the Jacobian matrix simply represents all first-order partial derivatives of a vector-valued function (in this case, we have a vector of training examples).\n",
    "\n",
    "For $n$ observations and $M$ hidden layer nodes (indexed by $m=1,2,3,...M$), we can calculate these values as follows:\n",
    "\n",
    "   - $||A||_{F}=\\sqrt{\\sum_{m=1}^{M}\\sum_{i=1}^{n}|a_{i,m}|^{2}}$\n",
    "   - $J=\\begin{bmatrix} \\frac{\\partial a_{1}^{(h)}(x)}{\\partial x_{1}}  & ... & \\frac{\\partial a_{1}^{(h)}(x)}{\\partial x_{n}} \\\\ ... & ... & ...\\\\ \\frac{\\partial a_{M}^{(h)}(x)}{\\partial x_{1}} & ... & \\frac{\\partial a_{M}^{(h)}(x)}{\\partial x_{n}} \\end{bmatrix}$\n",
    "\n",
    "Written more succinctly, we can define our complete loss function as the original loss function plus the term: $\\lambda\\sum_{i}||\\nabla_{x} a^{(h)}(x)||^{2}$ (the gradient field of our hidden layer activations with respect to the input $x$, summed over all $i$ training examples).\n",
    "\n",
    "Autoencoders have many applications. Two of the most important applications are data compression (for both image and tabular data) as well as outlier detection. The literature in outlier detection is rich and researchers have had many existing algorithms such as **local outlier factor**, **isolation forests**, **one-class SVM**, **hidden Markov models**, **deviations from association rules and frequent itemsets**, **feature bagging (random subspace bagging)** etc. However, autoencoders and **Baynesian networks** stand as two algorithms based on deep learning. And they have wide applications in many real world problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. An MNIST Example\n",
    "\n",
    "We now use an simple example to see how autoencoders perform on a toy dataset. To build an antoencoder, we will need 3 things: an encoding function , a decoding function, and a distance function between the amount of information loss between the compressed representation of the data and the decompressed representation. \n",
    "\n",
    "Below is a code sample using TensorFlow applied to the MNIST dataset. The encoder will consist of a stack of 2D convolutionary layers and 2D max-pooling layers (for spatial downsampling), while the decoder will consist of a stack of 2D convoluationary layers and 2D upsampling layers (the corresponding Python class in TensorFlow is UpSampling2D() which exists in TensorFlow version 2.6 above in the 'keras' module). Before we build the toy example of autoencoders on the MNIST data, let's first look at what upsampling is in TensorFlow.\n",
    "\n",
    "The upsampling concept really comes from a sub-field of deep learning techniques called **Generative Adversarial Networks (GANs)**, which are architecture for training generative models, such as deep convolutional neural networks for generating images. The idea is to use existing data to train a network that can produce something similar to the training dataset. An example is chatbox automation task. Here, we are training a network to learn how to talk like a real person. Another one is to generate random images based on existing data. GANs in general are complicated topics so we will not go into details now. But the most important thing is to realize what it does for the time being. \n",
    "\n",
    "The GAN architecture can be comprised of both a **generator model** and a **discriminator model**. We will not discuss the latter and only touch on the former. The generator model is responsible for creating new outputs, such as images, that plausibly could have come from the original dataset. The generator model is typically implemented using a deep convolutional neural network and results-specialized layers that learn to fill in features in an image rather than extract features from an input image.\n",
    "\n",
    "Two common types of layers that can be used in the generator model are upsample layers that simply double the dimensions of the input and the transpose convolutional layers that perform inverse convolution operations. For the upsampling layer, this is where the UpSampling() layer comes in play. Here is what UpSampling2D() looks like:\n",
    "\n",
    "   -  UpSampling2D(_size_=(2, 2), _data\\_format_=None, _interpolation_='nearest', _kwargs_)\n",
    "\n",
    "This class simply repeats the rows and columns of the data by size[0] and size[1] respectively. The input must be a 4D tensor. In particular:\n",
    "\n",
    "   - if _data\\_format_ is \"channels_last\": then the tensor should be arranged as (batch_size, rows, cols, channels)\n",
    "   - if _data\\_format_ is \"channels_first\": (batch_size, channels, rows, cols)\n",
    "\n",
    "Below is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0:  [ 0  1  2  3  4  5  6  7  8  9 10 11] \n",
      "----------\n",
      "\n",
      "[[[[ 0  1  2]]\n",
      "\n",
      "  [[ 3  4  5]]]\n",
      "\n",
      "\n",
      " [[[ 6  7  8]]\n",
      "\n",
      "  [[ 9 10 11]]]]\n"
     ]
    }
   ],
   "source": [
    "input_shape = (2, 2, 1, 3)\n",
    "x0= np.arange(np.prod(input_shape))  # 2*2*1*3=12\n",
    "x = x0.reshape(input_shape)\n",
    "print(\"x0: \", x0, \"\\n----------\\n\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[ 0  1  2]\n",
      "   [ 0  1  2]]\n",
      "\n",
      "  [[ 3  4  5]\n",
      "   [ 3  4  5]]]\n",
      "\n",
      "\n",
      " [[[ 6  7  8]\n",
      "   [ 6  7  8]]\n",
      "\n",
      "  [[ 9 10 11]\n",
      "   [ 9 10 11]]]], shape=(2, 2, 2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "y =  UpSampling2D(size=(1, 2))(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[ 0  1  2]\n",
      "   [ 0  1  2]]\n",
      "\n",
      "  [[ 0  1  2]\n",
      "   [ 0  1  2]]\n",
      "\n",
      "  [[ 3  4  5]\n",
      "   [ 3  4  5]]\n",
      "\n",
      "  [[ 3  4  5]\n",
      "   [ 3  4  5]]]\n",
      "\n",
      "\n",
      " [[[ 6  7  8]\n",
      "   [ 6  7  8]]\n",
      "\n",
      "  [[ 6  7  8]\n",
      "   [ 6  7  8]]\n",
      "\n",
      "  [[ 9 10 11]\n",
      "   [ 9 10 11]]\n",
      "\n",
      "  [[ 9 10 11]\n",
      "   [ 9 10 11]]]], shape=(2, 4, 2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "z =  UpSampling2D(size=(2, 2))(x)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build the autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 8)         1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 8)           584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 8)           584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 8, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 8)           584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 16, 16, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 16)        1168      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 1)         145       \n",
      "=================================================================\n",
      "Total params: 4,385\n",
      "Trainable params: 4,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Below is the encoder structure, with input dimension (28, 28, 1)\n",
    "input_img=Input(shape=(28,28,1))\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2,2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# Below is the decoder structure, and at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # this can be adapted if we are using 'channels_first' image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 55s 118ms/step - loss: 0.3194 - val_loss: 0.3085\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 55s 116ms/step - loss: 0.2976 - val_loss: 0.2905\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 54s 115ms/step - loss: 0.2837 - val_loss: 0.2797\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 54s 115ms/step - loss: 0.2753 - val_loss: 0.2731\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 54s 115ms/step - loss: 0.2700 - val_loss: 0.2687\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 55s 118ms/step - loss: 0.2662 - val_loss: 0.2652\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 55s 118ms/step - loss: 0.2632 - val_loss: 0.2625\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 54s 115ms/step - loss: 0.2606 - val_loss: 0.2601\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 54s 115ms/step - loss: 0.2584 - val_loss: 0.2580\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 54s 115ms/step - loss: 0.2564 - val_loss: 0.2560\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=10, # 50 is better\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))\n",
    "\n",
    "decoded_imgs = autoencoder.predict(x_test)\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(1,n+1):\n",
    "    # displaying the original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    # displaying reconstruction\n",
    "    ax = plt.subplot(2, n, i + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References: \n",
    "\n",
    "   - https://www.jeremyjordan.me/autoencoders/\n",
    "   - https://www.jeremyjordan.me/variational-autoencoders/\n",
    "   - https://web.stanford.edu/class/cs294a/sparseAutoencoder_2011new.pdf\n",
    "   - https://arxiv.org/pdf/1601.00670.pdf \n",
    "   - https://towardsdatascience.com/applied-deep-learning-part-3-autoencoders-1c083af4d798\n",
    "   - https://github.com/ardendertat/Applied-Deep-Learning-with-Keras/blob/master/notebooks/Part%203%20-%20Autoencoders.ipynb\n",
    "   - https://stackoverflow.com/questions/62879232/how-do-i-use-latex-in-a-jupyter-notebook-inside-visual-studio-code \n",
    "   - https://blog.keras.io/building-autoencoders-in-keras.html \n",
    "   - https://towardsdatascience.com/autoencoders-bits-and-bytes-of-deep-learning-eaba376f23ad \n",
    "   - https://medium.com/ai%C2%B3-theory-practice-business/anomaly-detection-part-1-autoencoder-58bdbbea5001 \n",
    "   - https://machinelearningmastery.com/upsampling-and-transpose-convolution-layers-for-generative-adversarial-networks/\n",
    "   - https://www.tensorflow.org/versions/r2.6/api_docs/python/tf/keras/layers/UpSampling2D\n",
    "   - https://arxiv.org/abs/1211.4246 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
